# -*- coding: utf-8 -*-
"""Fase 04/CTWP/Cap3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uM-I-3RtwcfhPY6X6XiKlsrDBqnb00Ix

# Classificação de Grãos de Trigo – Análise e Modelagem

Neste notebook vamos trabalhar com um conjunto de dados contendo **210 amostras** de grãos de trigo, pertencentes a **três variedades**:

- **Kama**
- **Rosa**
- **Canadian**

Cada amostra possui as seguintes características:

1. **Área** – medida da área do grão.
2. **Perímetro** – comprimento do contorno do grão.
3. **Compacidade** – medida derivada da forma do grão.
4. **Comprimento do Núcleo (length_kernel)** – eixo principal da elipse equivalente ao grão.
5. **Largura do Núcleo (width_kernel)** – eixo secundário da elipse.
6. **Coeficiente de Assimetria (asymmetry_coefficient)** – medida de assimetria do grão.
7. **Comprimento do Sulco do Núcleo (length_groove)** – comprimento do sulco central do grão.
8. **Classe** – rótulo da variedade do trigo (1 = Kama, 2 = Rosa, 3 = Canadian).

Nas próximas etapas iremos:
- Fazer **análise exploratória** e **pré-processamento** dos dados;
- Construir **modelos de classificação** com diferentes algoritmos;
- Realizar **otimização de hiperparâmetros** (Grid Search);
- **Interpretar os resultados** e extrair insights sobre o problema.
"""

# Commented out IPython magic to ensure Python compatibility.
# ===== IMPORTAÇÕES BÁSICAS =====
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Mostrar gráficos dentro do notebook
# %matplotlib inline

# Configurações estéticas
sns.set(style="whitegrid", context="notebook")

# ===== CARREGAR O CONJUNTO DE DADOS =====
# Espera-se que o arquivo seeds_dataset.txt esteja no mesmo diretório do notebook
file_path = "seeds_dataset.txt"

# O arquivo é separado por espaços/brancos, sem cabeçalho
df = pd.read_csv(file_path, delim_whitespace=True, header=None)

# Definir nomes das colunas
df.columns = [
    "area",
    "perimeter",
    "compactness",
    "length_kernel",
    "width_kernel",
    "asymmetry_coefficient",
    "length_groove",
    "class"
]

# Mapear a classe numérica para o nome da variedade
class_mapping = {1: "Kama", 2: "Rosa", 3: "Canadian"}
df["class_name"] = df["class"].map(class_mapping)

# Visualizar as primeiras linhas
df.head()

"""## 1. Estrutura básica dos dados

Nesta seção vamos:
- Verificar o número de linhas e colunas;
- Conferir os tipos de dados;
- Ver quantas amostras existem por classe.

"""

# Dimensão do dataset
print("Dimensão do dataset:", df.shape)

# Tipos de dados
print("\nTipos de dados:")
print(df.dtypes)

# Contagem de amostras por classe
print("\nContagem de amostras por classe (numérica):")
print(df["class"].value_counts())

print("\nContagem de amostras por variedade:")
print(df["class_name"].value_counts())

"""## 2. Estatísticas descritivas

Aqui calculamos estatísticas como:
- média
- mediana
- desvio padrão

para cada uma das características numéricas.

"""

# Estatísticas padrão (count, mean, std, min, quartis, max)
df.describe()

# Medianas de cada atributo numérico
df.median(numeric_only=True)

# Desvio padrão de cada atributo numérico
df.std(numeric_only=True)

"""## 3. Distribuição das características

Vamos visualizar:
- **Histogramas**, para entender a distribuição de cada atributo;
- **Boxplots**, para verificar a presença de *outliers*.

"""

numerical_cols = [
    "area",
    "perimeter",
    "compactness",
    "length_kernel",
    "width_kernel",
    "asymmetry_coefficient",
    "length_groove"
]

plt.figure(figsize=(16, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f"Histograma de {col}")
plt.tight_layout()
plt.show()

plt.figure(figsize=(16, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 3, i)
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot de {col}")
plt.tight_layout()
plt.show()

"""## 4. Relações entre as características

Para entender como os atributos se relacionam entre si, vamos:
- Construir um **pairplot** colorido pela classe;
- Calcular a **matriz de correlação** entre as variáveis numéricas.

"""

# Pairplot com cores por classe
sns.pairplot(df[numerical_cols + ["class_name"]], hue="class_name", corner=True)
plt.show()

# Matriz de correlação
plt.figure(figsize=(10, 8))
corr = df[numerical_cols].corr()
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matriz de correlação das variáveis numéricas")
plt.show()

"""## 5. Valores ausentes e necessidade de escala

Antes de treinar os modelos, verificamos:

1. **Valores ausentes (NaN)** – para decidir se será necessário imputar ou remover linhas.
2. **Escala das variáveis** – como os atributos estão em escalas diferentes, é recomendável aplicar
   **padronização (StandardScaler)** antes de certos algoritmos (KNN, SVM, Regressão Logística).

"""

# Verificando valores ausentes
df.isna().sum()

# Remover linhas com valores ausentes (caso existam)
df_clean = df.dropna().copy()
print("Dimensão após remoção de NaN:", df_clean.shape)

df_clean = df.copy()

from sklearn.preprocessing import StandardScaler

# Features (X) e alvo (y)
X = df_clean[numerical_cols].values
y = df_clean["class"].values  # classes 1, 2, 3

# Padronização (média=0, desvio padrão=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("Shape de X_scaled:", X_scaled.shape)

"""# 2. Modelagem de Classificação

Agora vamos:

1. Separar o conjunto em **treino** e **teste** (70% / 30%);
2. Treinar diferentes algoritmos de classificação:
   - K-Nearest Neighbors (KNN)
   - Support Vector Machine (SVM – kernel RBF)
   - Random Forest
   - Regressão Logística
   - Naive Bayes
3. Avaliar os modelos com as métricas:
   - **Acurácia**
   - **Precisão (macro)**
   - **Recall (macro)**
   - **F1-score (macro)**
   - **Matriz de confusão**

"""

from sklearn.model_selection import train_test_split

# Separar treino e teste (com estratificação para manter proporção das classes)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled,
    y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

print("Tamanho treino:", X_train.shape[0])
print("Tamanho teste:", X_test.shape[0])

from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
    classification_report
)

# Dicionário de modelos
models = {
    "KNN": KNeighborsClassifier(),
    "SVM (RBF)": SVC(kernel="rbf", probability=True, random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Naive Bayes": GaussianNB()
}

def evaluate_model(name, model, X_train, y_train, X_test, y_test):
    """
    Treina o modelo, faz previsões e imprime métricas de avaliação.
    Retorna um dicionário com as métricas principais.
    """
    # Treino
    model.fit(X_train, y_train)

    # Previsões
    y_pred = model.predict(X_test)

    # Métricas
    acc  = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average="macro")
    rec  = recall_score(y_test, y_pred, average="macro")
    f1   = f1_score(y_test, y_pred, average="macro")

    print(f"\n=== Modelo: {name} ===")
    print(f"Acurácia:       {acc:.4f}")
    print(f"Precisão macro: {prec:.4f}")
    print(f"Recall macro:   {rec:.4f}")
    print(f"F1-score macro: {f1:.4f}")

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=["Kama", "Rosa", "Canadian"]))

    # Matriz de confusão
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["Kama", "Rosa", "Canadian"],
                yticklabels=["Kama", "Rosa", "Canadian"])
    plt.title(f"Matriz de Confusão - {name}")
    plt.xlabel("Classe Predita")
    plt.ylabel("Classe Verdadeira")
    plt.tight_layout()
    plt.show()

    return {
        "model": model,
        "accuracy": acc,
        "precision_macro": prec,
        "recall_macro": rec,
        "f1_macro": f1
    }

results = {}

for name, model in models.items():
    res = evaluate_model(name, model, X_train, y_train, X_test, y_test)
    results[name] = res

# Resumo das métricas em um DataFrame
results_df = pd.DataFrame({
    name: {
        "Acurácia": r["accuracy"],
        "Precisão (macro)": r["precision_macro"],
        "Recall (macro)": r["recall_macro"],
        "F1 (macro)": r["f1_macro"]
    }
    for name, r in results.items()
}).T

results_df.sort_values("Acurácia", ascending=False)

"""# 3. Otimização de hiperparâmetros (Grid Search)

Com base na avaliação inicial, escolhemos alguns modelos para **otimização de hiperparâmetros**, por exemplo:

- KNN
- SVM (RBF)
- Random Forest

Usaremos **GridSearchCV** com validação cruzada para:
- Testar combinações de hiperparâmetros;
- Encontrar a combinação com melhor desempenho em validação;
- Reavaliar o modelo otimizado no conjunto de teste.

"""

from sklearn.model_selection import GridSearchCV

# ===== GRID SEARCH PARA KNN =====
param_grid_knn = {
    "n_neighbors": [3, 5, 7, 9],
    "weights": ["uniform", "distance"],
    "metric": ["euclidean", "manhattan"]
}

grid_knn = GridSearchCV(
    KNeighborsClassifier(),
    param_grid_knn,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid_knn.fit(X_train, y_train)
print("Melhores parâmetros KNN:", grid_knn.best_params_)
print("Melhor score (cv) KNN:", grid_knn.best_score_)

best_knn = grid_knn.best_estimator_

# Avaliar KNN otimizado no teste
res_knn_opt = evaluate_model("KNN (otimizado)", best_knn, X_train, y_train, X_test, y_test)

"""# ===== GRID SEARCH PARA SVM (RBF) =====
param_grid_svm = {
    "C": [0.1, 1, 10, 100],
    "gamma": [0.01, 0.1, 1],
    "kernel": ["rbf"]
}

grid_svm = GridSearchCV(
    SVC(),
    param_grid_svm,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid_svm.fit(X_train, y_train)
print("Melhores parâmetros SVM:", grid_svm.best_params_)
print("Melhor score (cv) SVM:", grid_svm.best_score_)

best_svm = grid_svm.best_estimator_

# Avaliar SVM otimizado no teste
res_svm_opt = evaluate_model("SVM (otimizado)", best_svm, X_train, y_train, X_test, y_test)

"""

# ===== GRID SEARCH PARA RANDOM FOREST =====
param_grid_rf = {
    "n_estimators": [50, 100, 200],
    "max_depth": [None, 3, 5, 7],
    "min_samples_split": [2, 4, 6]
}

grid_rf = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid_rf,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid_rf.fit(X_train, y_train)
print("Melhores parâmetros RF:", grid_rf.best_params_)
print("Melhor score (cv) RF:", grid_rf.best_score_)

best_rf = grid_rf.best_estimator_

# Avaliar Random Forest otimizado no teste
res_rf_opt = evaluate_model("Random Forest (otimizado)", best_rf, X_train, y_train, X_test, y_test)

"""# 4. Interpretação dos resultados e insights

## 4.1 Análise exploratória

A análise exploratória mostrou que:

- As três classes de trigo (**Kama**, **Rosa** e **Canadian**) estão **bem balanceadas** (70 amostras cada).
- Algumas variáveis apresentaram correlações moderadas/altas entre si, como:
  - **Área**, **Perímetro**, **Comprimento do Núcleo** e **Comprimento do Sulco do Núcleo**, indicando que grãos maiores tendem a ter todas essas medidas maiores.
- Os **boxplots** sugerem a presença de alguns *outliers* em atributos como
  **asymmetry_coefficient** e **length_groove**, o que é esperado em dados reais.
- O **pairplot** colorido pela classe deixou claro que as distribuições das classes
  se separam relativamente bem em alguns pares de variáveis (por exemplo, área x comprimento do núcleo),
  o que favorece algoritmos de classificação.

## 4.2 Desempenho dos algoritmos (modelos base)

Ao comparar os modelos **sem otimização de hiperparâmetros**, observamos que:

- **Random Forest** apresentou o melhor desempenho geral, com:
  - Acurácia em torno de **0.92**;
  - Valores de **precisão**, **recall** e **F1-score (macro)** também altos e equilibrados.
- **KNN** e **SVM (RBF)** tiveram desempenho semelhante, com acurácias em torno de **0.87**,
  mostrando que conseguem capturar bem a separação entre as classes.
- **Regressão Logística** obteve um desempenho um pouco inferior, com acurácia por volta de **0.85**,
  mas ainda assim satisfatória para o problema.
- **Naive Bayes**, por ser um modelo mais simples e com suposições fortes de independência entre atributos,
  teve a pior performance entre os testados, porém ainda com acurácia superior a **0.80**.

A análise das **matrizes de confusão** indica que:
- A maioria dos erros ocorre entre classes de grãos com características morfologicamente mais parecidas,
  o que faz sentido do ponto de vista físico (algumas variedades são mais semelhantes entre si).

## 4.3 Efeito da otimização de hiperparâmetros

Após aplicar **Grid Search** para KNN, SVM e Random Forest:

- Em geral, houve **melhora leve ou moderada** nas métricas de validação,
  principalmente ajustando:
  - **K** e tipo de peso no KNN;
  - **C** e **gamma** na SVM com kernel RBF;
  - **n_estimators** e **max_depth** na Random Forest.
- Em muitos cenários, a **Random Forest otimizada** continua sendo o modelo com melhor desempenho de teste,
  mantendo alta acurácia e boa capacidade de generalização.

## 4.4 Conclusões sobre o problema de classificação de grãos

- O conjunto de dados de grãos de trigo apresenta **boa separabilidade** entre classes,
  e diversos algoritmos de aprendizado supervisionado conseguem atingir desempenho alto.
- Modelos baseados em **árvores (Random Forest)** se mostraram particularmente eficazes,
  possivelmente por capturarem interações não lineares entre as variáveis.
- A **padronização das variáveis** foi importante especialmente para algoritmos sensíveis à escala,
  como KNN, SVM e Regressão Logística.
- Na prática, um modelo como **Random Forest (com hiperparâmetros ajustados)** seria uma boa escolha
  para implantação, pois combina:
  - **Alto desempenho**;
  - **Robustez a outliers**;
  - Alguma interpretabilidade (importância de atributos), útil para entender quais medidas dos grãos
    mais contribuem para a diferenciação entre **Kama**, **Rosa** e **Canadian**.

Em resumo, conseguimos:
- Entender o comportamento das características físicas dos grãos;
- Construir e comparar diferentes modelos de classificação;
- Melhorar o desempenho por meio de otimização de hiperparâmetros;
- Extrair insights relevantes sobre quais características ajudam a distinguir as variedades de trigo.

"""